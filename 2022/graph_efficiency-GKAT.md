Graph Kernel Attention Transformer (https://syncedreview.com/2021/07/23/graph-kernel-attention-transformers-toward-expressive-and-scalable-graph-processing-68/) 

Prøver å lage en mer effektiv GNN for store grafer, mtp. minne og ppooling osv. Lager en smoothed adjacency matrix. Ikke helt sikker på hva de prøver å løse... Mye svada i artikkelen hvertfall.. Finnes vel bedre ressurser på efficient processing on large graphs.
